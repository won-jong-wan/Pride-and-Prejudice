from pathlib import Path
import tempfile, streamlit as st
from core.whisper import transcribe_file
from core.analysis_pose import parse_posture_summary
from core.analysis_audio import analyze_stability, get_stability_score



# â”€â”€ ì—…ë¡œë“œ ëª¨ë“œ(ë°°ì¹˜ ë¶„ì„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_upload_section(*, SAVE_DIR: Path, ss, whisper_model, feedback_chain):
    with st.expander("ğŸ“¤ ì—…ë¡œë“œ ëª¨ë“œ", expanded=False):
        # ì„¸ì…˜ë³„ ê¸°ë¡ ë³´ê´€
        ss.setdefault("chapters", [])
        ss.setdefault("history", [])
        ss.setdefault("uploader_key", 0)
        ss.setdefault("posture_key", 0)

        if st.button("ğŸ†• ìƒˆë¡œìš´ ë©´ì ‘ ì‹œì‘"):
            if ss["history"]:
                ss["chapters"].append(ss["history"])
            ss["history"] = []
            ss["uploader_key"] += 1
            ss["posture_key"] += 1
            st.rerun()

        st.markdown(
            """
            <div style="
                background-color:#f0f8ff; padding:20px; border-radius:12px;
                text-align:center; border: 1px solid #1E90FF; margin-bottom:15px;">
                <h3 style="color:#1E90FF;">ğŸ™ï¸ ë©´ì ‘ ë‹µë³€ ì—…ë¡œë“œ</h3>
                <p style="color:#333;">ì§€ì›ìì˜ ìŒì„±ê³¼ ìì„¸ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.<br>
                ì§€ì› í˜•ì‹: <b>WAV, M4A, MP3, FLAC, XML</b></p>
            </div>
            """,
            unsafe_allow_html=True
        )

        uploaded_file = st.file_uploader("ğŸ™ï¸ ìŒì„± ë°ì´í„°", type=["wav","m4a","mp3","flac"], key=f"file_uploader_{ss['uploader_key']}")
        posture_file  = st.file_uploader("ğŸ§ ìì„¸ ë°ì´í„°", type=["xml"], key=f"posture_uploader_{ss['posture_key']}")

        # ìì„¸ ìš”ì•½
        posture_summary = None
        if posture_file:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xml") as tmp_xml:
                tmp_xml.write(posture_file.getbuffer())
                posture_summary = parse_posture_summary(tmp_xml.name)

        if uploaded_file and posture_file:
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}, {posture_file.name}")
            st.audio(uploaded_file)

            # ì„ì‹œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(uploaded_file.getbuffer())
                wav_path = tmp_file.name

            with st.spinner("ë¶„ì„ ì¤‘..."):
                # 1) Whisper ì „ì‚¬
                whisper_res = transcribe_file(ss["whisper_model"], wav_path, language="ko")
                transcript = whisper_res.get("text", "")
                
                # 2) ìŒì„± í”¼ì²˜
                features, _ = analyze_stability(wav_path)
                jitter   = features["jitter"]
                shimmer  = features["shimmer"]
                hnr      = features["hnr"]

                # 3) ì•ˆì •ì„± ì ìˆ˜
                stability_score, voice_label, color = get_stability_score(jitter=jitter, shimmer=shimmer, hnr=hnr)

                # 4) LLM í”¼ë“œë°±
                feedback = ss["feedback_chain"].run({
                    "transcript": transcript,
                    "stability_score": stability_score,
                    "label": voice_label,
                    "posture": posture_summary["label"] if posture_summary else "ë°ì´í„° ì—†ìŒ"
                })

                # 5) ê²°ê³¼ ì €ì¥(ë©”ëª¨ë¦¬)
                result = {
                    "transcript": transcript, "jitter": jitter, "shimmer": shimmer,
                    "stability_score": stability_score, "voice_label": voice_label, "color": color,
                    "posture": posture_summary["label"] if posture_summary else "ë°ì´í„° ì—†ìŒ",
                    "feedback": feedback
                }
                ss["history"].append(result)

        # ê²°ê³¼ ë Œë”
        def render_question_result(i, res):
            st.markdown(f"### â“ ë‹µë³€ {i}")
            st.info(res["transcript"])

            c1, c2 = st.columns([1, 2])
            with c1:
                st.metric("ğŸšï¸ Jitter (í”¼ì¹˜ í”ë“¤ë¦¼)", f"{res['jitter']:.4f}")
                st.metric("ğŸ”‰ Shimmer (ë³¼ë¥¨ í”ë“¤ë¦¼)", f"{res['shimmer']:.4f}")
            with c2:
                score = float(res.get("stability_score", 0))
                st.metric("ëª©ì†Œë¦¬ ì•ˆì •ì„± ì ìˆ˜", f"{score:.2f}/10")
                st.progress(min(1.0, score/10))

            label = res.get("voice_label", "ë°ì´í„° ì—†ìŒ")
            color = res.get("color", "warning")
            if color == "success":   st.success(f"âœ… ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")
            elif color == "warning": st.warning(f"âš ï¸ ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")
            else:                    st.error(f"âŒ ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")

            if "posture" in res:
                text = res["posture"]
                if "ì•ˆì •ì " in text: st.success(f" ìì„¸: {text}")
                elif ("ë¶ˆì•ˆì •" in text) or ("ê¸°ìš¸ì–´ì§" in text): st.error(f" ìì„¸: {text}")
                else: st.warning(f" ìì„¸: {text}")

            st.success(res["feedback"])
            st.divider()

        if ss["history"] or ss["chapters"]:
            st.subheader("ğŸ“‚ ë©´ì ‘ ê¸°ë¡")
            if ss["history"]:
                st.markdown("## ğŸš€ í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë©´ì ‘")
                for i, res in enumerate(ss["history"], 1):
                    render_question_result(i, res)
            for c_idx, chapter in enumerate(ss["chapters"], 1):
                with st.expander(f"ğŸ“Œ ê³¼ê±° ë©´ì ‘ ì„¸ì…˜ {c_idx}", expanded=False):
                    for i, res in enumerate(chapter, 1):
                        render_question_result(i, res)
