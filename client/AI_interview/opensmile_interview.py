import streamlit as st
import os
import numpy as np
import librosa
import scipy.ndimage
import tempfile

# ============================
# 0ï¸âƒ£ API í‚¤ ì„¤ì •
# ============================
# Google GenAI
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY", "AIzaSyDuI6DK3v17kGqqSyM4uHRWoC2qRC-Kzpg")
# ============================
# 1ï¸âƒ£ Whisper STT
# ============================

import whisper
import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("small")  # small/medium/large ì„ íƒ

def run_whisper(audio_file):
    result = model.transcribe(audio_file, language="ko")
    return result["text"]
print("í˜„ì¬ ì¥ì¹˜:", device)
# ============================
# 2ï¸âƒ£ ëª©ì†Œë¦¬ ì•ˆì •ì„± ë¶„ì„
# ============================
import opensmile
import pandas as pd

# ğŸ”¹ openSMILE ì´ˆê¸°í™”
smile = opensmile.Smile(
    feature_set=opensmile.FeatureSet.eGeMAPSv02,
    feature_level=opensmile.FeatureLevel.Functionals,
)

def analyze_stability(audio_path: str):
    """ìŒì„± ì•ˆì •ì„± í”¼ì²˜ ì¶”ì¶œ"""
    result = smile.process_file(audio_path).iloc[0]

    features = {
        "jitter": result["jitterLocal_sma3nz_amean"],
        "shimmer": result["shimmerLocaldB_sma3nz_amean"],
        "hnr": result["HNRdBACF_sma3nz_amean"],
        "f0_std": result["F0semitoneFrom27.5Hz_sma3nz_stddevNorm"],
        "loudness_std": result["loudness_sma3_stddevNorm"],
    }
    return features, "ok"

def get_stability_score(jitter, shimmer,hnr):
      # 1ï¸âƒ£ ê¸°ì¤€ê°’ ì™„í™” (ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ)
    JITTER_REF = 0.05      # í˜„ì‹¤ ê¸°ì¤€ìœ¼ë¡œ ì•½ 3ë°° ì™„í™”
    SHIMMER_REF = 0.45   # ê¸°ì¡´ 0.10ë³´ë‹¤ ì™„í™”
    HNR_REF_GOOD = 15.0
    HNR_REF_BAD = 10.0

    # 2ï¸âƒ£ ê°œë³„ ì ìˆ˜ (0~10)
    # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ jitter/shimmer â†’ 1 - (value/ref)
    score_jitter = max(0, 1 - (jitter / JITTER_REF))
    score_shimmer = max(0, 1 - (shimmer / SHIMMER_REF))
    
    # HNRì€ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ (value / 20)ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
    # 20dB ì´ìƒì´ë©´ ë§¤ìš° ì¢‹ì€ ìŒì§ˆ
    score_hnr = min(1.0, max(0, hnr / 20.0))

    # 3ï¸âƒ£ ê°€ì¤‘ í‰ê·  (jitter/shimmer 40%, HNR 20%)
    score = (score_jitter * 0.3 + score_shimmer * 0.3 + score_hnr * 0.4) * 10

    # 4ï¸âƒ£ ìŠ¤ì¼€ì¼ ë³´ì • (ì „ì²´ ì ìˆ˜ ìƒí–¥)
    score = min(10.0, (score * 1.2) + 1.0)
    # 4ï¸âƒ£ ë¼ë²¨ ê²°ì •
    if score >= 8.0:
        label, color = "ì•ˆì •ì  âœ…", "success"
    elif score >= 5.0:
        label, color = "ë³´í†µ âš ï¸", "warning"
    else:
        label, color = "ë¶ˆì•ˆì • âŒ", "error"

    return round(score, 2), label, color


# ============================
# 3ï¸âƒ£ ìì„¸ ë¶„ì„
# ============================
import xml.etree.ElementTree as ET

import xml.etree.ElementTree as ET

def parse_posture_summary(xml_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()

    head_tilt_count = 0
    body_tilt_count = 0
    gesture_count = 0
    frame_total = 0

    for frame in root.findall("frame"):
        frame_total += 1
        analysis = frame.find("analysis")
        if analysis is None:
            continue

        for result in analysis.findall("result"):
            rtype = result.get("type", "")
            if rtype == "head_tilt":
                head_tilt_count += 1
            elif rtype == "body_tilt":
                body_tilt_count += 1
            elif rtype == "gesture":
                gesture_count += 1

    # ê¸°ë³¸ ë¼ë²¨ë§
    labels = []
    if head_tilt_count > frame_total * 0.3:
        labels.append("ë¨¸ë¦¬ ê¸°ìš¸ì„ ì¦ìŒ")
    if body_tilt_count > frame_total * 0.3:
        labels.append("ëª¸ ê¸°ìš¸ì–´ì§ ì¦ìŒ")

    # ì œìŠ¤ì²˜ ë¼ë²¨ë§
    if gesture_count == 0:
        gesture_label = "ì œìŠ¤ì²˜ ì—†ìŒ (ë‹µë³€ì´ ë”±ë”±í•  ìˆ˜ ìˆìŒ)"
    elif 1 <= gesture_count <= 3:
        gesture_label = "ìì—°ìŠ¤ëŸ¬ìš´ ì œìŠ¤ì²˜ ì‚¬ìš©"
    else:
        gesture_label = "ì œìŠ¤ì²˜ ê³¼ë‹¤ (ì‚°ë§Œí•  ìˆ˜ ìˆìŒ)"

    labels.append(gesture_label)

    return {
        "frames": frame_total,
        "head_tilt_count": head_tilt_count,
        "body_tilt_count": body_tilt_count,
        "gesture_count": gesture_count,
        "label": ", ".join(labels)
    }


# ============================
# 4ï¸âƒ£ Google GenAI + LangChain
# ============================
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.6,
    api_key=GOOGLE_API_KEY
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "ë„ˆëŠ” ì „ë¬¸ ë©´ì ‘ê´€ ì—­í• ì„ ë§¡ëŠ”ë‹¤. ì•„ë˜ëŠ” ë©´ì ‘ìì˜ í–‰ë™ ë¶„ì„ ë°ì´í„°ì´ë‹¤. ì´ ë°ì´í„°ì—ëŠ” ë©´ì ‘ ì¤‘ ê°ì§€ëœ ìì„¸, í‘œì •, ìŒì„±ì˜ íŠ¹ì§•ì´ í¬í•¨ëœë‹¤."),
    ("human", """
ë©´ì ‘ ë‹µë³€ ë¶„ì„:
- Transcript: {transcript}

[ìŒì„± ë¶„ì„ ê²°ê³¼]
- í”¼ì¹˜ í”ë“¤ë¦¼ (Jitter): {jitter:.4f}
- ë³¼ë¥¨ í”ë“¤ë¦¼ (Shimmer): {shimmer:.4f}
- ë°°ìŒëŒ€ì¡ìŒë¹„ (HNR): {hnr:.2f} dB
- í”¼ì¹˜ í‘œì¤€í¸ì°¨ (F0_std): {f0_std:.2f}
- ë³¼ë¥¨ í‘œì¤€í¸ì°¨ (Loudness_std): {loudness_std:.2f}
- ì „ë°˜ì  í‰ê°€: {label}

ìì„¸ ë° ì œìŠ¤ì²˜ í™œìš©: {posture}

ìš”êµ¬ì‚¬í•­:
1. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ìì˜ í–‰ë™ì„ **ê°ê´€ì ìœ¼ë¡œ ìš”ì•½**í•œë‹¤. (ìˆ«ì, íšŸìˆ˜ í¬í•¨)
2. ë©´ì ‘ê´€ì˜ ì…ì¥ì—ì„œ ë©´ì ‘ìì—ê²Œ ë„ì›€ì´ ë  **í”¼ë“œë°±ì„ 2~3ë¬¸ì¥**ìœ¼ë¡œ ì œì‹œí•œë‹¤.  
   - ê¸ì •ì ì¸ ë¶€ë¶„ì„ ë¨¼ì € ì§šê³ , ê°œì„ í•  ì ì„ ì œì•ˆí•œë‹¤.  
   - ë„ˆë¬´ ê³µê²©ì ì´ì§€ ë§ê³  **ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤**ì„ ìœ ì§€í•œë‹¤.  
3. í”¼ë“œë°±ì€ **ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ** ì‘ì„±í•œë‹¤.

ì¶œë ¥ í˜•ì‹:
- ë¶„ì„ ìš”ì•½: ...
- ê°•ì : ...
- í”¼ë“œë°±: ...
""")
])

chain = LLMChain(llm=llm, prompt=prompt)

chain = LLMChain(llm=llm, prompt=prompt)

# ============================
# streamlit ì‹¤í–‰
# ============================
st.set_page_config(page_title="AI ë©´ì ‘ê´€", page_icon="ğŸ¤", layout="wide")

# íƒ€ì´í‹€ + ì„œë¸Œíƒ€ì´í‹€
st.markdown(
    """
    <h1 style='text-align: center; color: #1E90FF; font-size: 40px;'>
        ğŸ¤ AI ë©´ì ‘ê´€
    </h1>
    <h3 style='text-align: center; color: #555;'>
        ë‹¹ì‹ ì˜ <b>ëª©ì†Œë¦¬ Â· ìì„¸ Â· í‘œì •</b>ì„ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤
    </h3>
    """,
    unsafe_allow_html=True
)


st.divider()

# ----------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ----------------------
if "chapters" not in st.session_state:
    st.session_state.chapters = []  # ì „ì²´ ë©´ì ‘ ê¸°ë¡ (ì„¸ì…˜ë³„)
if "history" not in st.session_state:
    st.session_state.history = []   # í˜„ì¬ ì„¸ì…˜ ê¸°ë¡

# ----------------------
# ìƒˆ ë©´ì ‘ ì„¸ì…˜ ì‹œì‘ ë²„íŠ¼
# ----------------------
if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = 0
if "posture_key" not in st.session_state:
    st.session_state.posture_key = 0

if st.button("ğŸ†• ìƒˆë¡œìš´ ë©´ì ‘ ì‹œì‘"):
    if st.session_state.history:
        st.session_state.chapters.append(st.session_state.history)
    st.session_state.history = []
    st.session_state.uploader_key += 1  # key ë°”ê¿”ì¤Œ
    st.session_state.posture_key += 1
    st.rerun()


# ì„œë¹„ìŠ¤ ì†Œê°œ ì¹´ë“œ
st.markdown(
    """
    <div style="
        background-color:#f0f8ff;
        padding:20px;
        border-radius:12px;
        text-align:center;
        border: 1px solid #1E90FF;
        margin-bottom:15px;
    ">
        <h3 style="color:#1E90FF;">ğŸ™ï¸ ë©´ì ‘ ë‹µë³€ ì—…ë¡œë“œ</h3>
        <p style="color:#333;">ì§€ì›ìì˜ ìŒì„±ê³¼ ìì„¸ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.<br>
        ì§€ì› í˜•ì‹: <b>WAV, M4A, MP3, FLAC, XML</b></p>
    </div>
    """,
    unsafe_allow_html=True
)
uploaded_file = st.file_uploader(
    "ğŸ™ï¸ ìŒì„± ë°ì´í„°",
    type=["wav","m4a","mp3","flac"],
    key=f"file_uploader_{st.session_state.uploader_key}"  # key ë§¤ë²ˆ ë°”ë€œ
)

posture_file = st.file_uploader(
    "ğŸ§ ìì„¸ ë°ì´í„°",
    type=["xml"],
    key=f"posture_uploader_{st.session_state.posture_key}" # key ë§¤ë²ˆ ë°”ë€œ
)
summary = None
if posture_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xml") as tmp_xml:
        tmp_xml.write(posture_file.getbuffer())
        summary = parse_posture_summary(tmp_xml.name)  # ìì„¸ ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš©

if uploaded_file and posture_file:
    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name, posture_file.name}")
    st.audio(uploaded_file)
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ 
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(uploaded_file.getbuffer())
        tmp_path = tmp_file.name

    with st.spinner("ë¶„ì„ ì¤‘..."):
        # 1ï¸âƒ£ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜
        transcript = run_whisper(tmp_path)

        # 2ï¸âƒ£ openSMILE ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œ
        features, _ = analyze_stability(tmp_path)
        jitter = features["jitter"]
        shimmer = features["shimmer"]

        # 3ï¸âƒ£ ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°
        stability_score, voice_label, color = get_stability_score(
        jitter=features["jitter"],
        shimmer=features["shimmer"],
        hnr=features["hnr"]
    )

        # 4ï¸âƒ£ LLM í”¼ë“œë°± ìƒì„±
        feedback = chain.run({
            "transcript": transcript,
            "jitter": features["jitter"],
            "shimmer": features["shimmer"],
            "hnr": features["hnr"],
            "f0_std": features["f0_std"],
            "loudness_std": features["loudness_std"],
            "label": voice_label,
            "posture": summary["label"] if summary else "ë°ì´í„° ì—†ìŒ"
        })
        

        # 5ï¸âƒ£ ê²°ê³¼ ì €ì¥
        result = {
            "transcript": transcript,
            "jitter": jitter,
            "shimmer": shimmer,
            "stability_score": stability_score,
            "voice_label": voice_label,
            "color": color,
            "posture": summary["label"] if summary else "ë°ì´í„° ì—†ìŒ",
            "feedback": feedback
        }

        st.session_state.history.append(result)


def render_question_result(i, res):
    st.markdown(f"### â“ ë‹µë³€ {i}")
    st.info(res["transcript"])

    col1, col2 = st.columns([1, 2])
    with col1:
        # openSMILE ê¸°ë°˜ ì£¼ìš” í”¼ì²˜ í‘œì‹œ
        st.metric("ğŸšï¸ Jitter (í”¼ì¹˜ í”ë“¤ë¦¼)", f"{res['jitter']:.4f}")
        st.metric("ğŸ”‰ Shimmer (ë³¼ë¥¨ í”ë“¤ë¦¼)", f"{res['shimmer']:.4f}")
    with col2:
        # ì•ˆì •ì„± ì ìˆ˜ ì‹œê°í™” (10ì  í™˜ì‚°)
        score = float(res.get("stability_score", 0))
        st.metric("ëª©ì†Œë¦¬ ì•ˆì •ì„± ì ìˆ˜", f"{score:.2f}/10")
        st.progress(score / 10)

    # ì•ˆì •ì„± ë¼ë²¨ ìƒ‰ìƒ í‘œì‹œ
    label = res.get("voice_label", "ë°ì´í„° ì—†ìŒ")
    color = res.get("color", "warning")

    if color == "success":
        st.success(f"âœ… ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")
    elif color == "warning":
        st.warning(f"âš ï¸ ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")
    else:
        st.error(f"âŒ ëª©ì†Œë¦¬ ì•ˆì •ì„±: {label}")

    if "posture" in res:
        if "ì•ˆì •ì " in res["posture"]:
            st.success(f" ìì„¸: {res['posture']}")
        elif "ë¶ˆì•ˆì •" in res["posture"] or "ê¸°ìš¸ì–´ì§" in res["posture"]:
            st.error(f" ìì„¸: {res['posture']}")
        else:
            st.warning(f" ìì„¸: {res['posture']}")

    st.success(f"{res['feedback']}")
    st.divider()


# ---------------- ê²°ê³¼ ì¶œë ¥ ----------------
if st.session_state.history or st.session_state.chapters:
    st.subheader("ğŸ“‚ ë©´ì ‘ ê¸°ë¡")

    # âœ… í˜„ì¬ ì„¸ì…˜
    if st.session_state.history:
        st.markdown("## ğŸš€ í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë©´ì ‘")
        for i, res in enumerate(st.session_state.history, 1):
            render_question_result(i, res)

    # âœ… ê³¼ê±° ì„¸ì…˜ (expanderë¡œ ì ‘ê¸°)
    for c_idx, chapter in enumerate(st.session_state.chapters, 1):
        with st.expander(f"ğŸ“Œ ê³¼ê±° ë©´ì ‘ ì„¸ì…˜ {c_idx}", expanded=False):
            for i, res in enumerate(chapter, 1):
                render_question_result(i, res)


# ----------------------
# í‘¸í„°
# ----------------------

st.divider()
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 14px;'>
        Â© 2025 AI Interview Project | Powered by Whisper Â· LangChain Â· Hailo
    </div>
    """,
    unsafe_allow_html=True
)